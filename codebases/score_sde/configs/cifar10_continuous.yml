data:
    dataset: "CIFAR10"
    image_size: 32
    channels: 3
    logit_transform: false
    uniform_dequantization: false
    gaussian_dequantization: false
    random_flip: true
    rescaled: true
    num_workers: 4
    num_classes: 10

model:
    model_type: "ncsnpp"
    scale_by_sigma: False
    ema_rate: 0.9999
    normalization: 'GroupNorm'
    nonlinearity: 'swish'
    nf: 128
    ch_mult: [1, 2, 2, 2]
    num_res_blocks: 8
    attn_resolutions: [16,]
    resamp_with_conv: True
    conditional: True
    fir: False
    fir_kernel: [1, 3, 3, 1]
    skip_rescale: True
    resblock_type: 'biggan'
    progressive: 'none'
    progressive_input: 'none'
    progressive_combine: 'sum'
    attention_type: 'ddpm'
    init_scale: 0.
    embedding_type: 'positional'
    fourier_scale: 16
    conv_size: 3
    sigma_min: 0.01
    sigma_max: 50
    num_scales: 1000
    beta_min: 0.1
    beta_max: 20.
    dropout: 0.1
    training:
        continuous: true
    #-------new-------#
    is_upsampling: false
    var_type: fixedlarge
    ema: True
    ckpt_dir: ./checkpoints/checkpoint_8.pth # path to model

diffusion:
    beta_schedule: linear
    beta_start: 0.0001
    beta_end: 0.02
    num_diffusion_timesteps: 1000

training:
    batch_size: 128
    n_epochs: 10000
    n_iters: 5000000
    snapshot_freq: 5000
    validation_freq: 2000

sampling:
    total_N: 1000
    batch_size: 1024
    last_only: false
    fid_image_dir: 
    fid_stats_dir: fid_stats/cifar10/fid_stats_cifar10_train_pytorch.npz # path to FID statistics
    fid_total_samples: 50000
    fid_batch_size: 256
    cond_class: false
    classifier_scale: 0.0
    #------new------#
    keep_samples: false
    continuous: false # means whether continue sampling from a number of generated images
    adaptive_tend: true
    time_input_type: "3"
    statistics_dir: "dpm_solver_v3/cifar10_ddpmpp_deep_continuous/0.0001_1200_4096"
    t_start: 1
    average_x0_path: "average_image.pth"

fixed_noise:
    enable: false
    path: fixed_noises/1024_3_32_32.pth # path to a set of fixed noise to decrease the randomness in evaluation

optim:
    weight_decay: 0.000
    optimizer: "Adam"
    lr: 0.0002
    beta1: 0.9
    amsgrad: false
    eps: 0.00000001
    grad_clip: 1.0
